{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>playername</th>\n",
       "      <th>teamname</th>\n",
       "      <th>result</th>\n",
       "      <th>kills</th>\n",
       "      <th>deaths</th>\n",
       "      <th>assists</th>\n",
       "      <th>teamkills</th>\n",
       "      <th>teamdeaths</th>\n",
       "      <th>firstblood</th>\n",
       "      <th>...</th>\n",
       "      <th>opp_csat15</th>\n",
       "      <th>golddiffat15</th>\n",
       "      <th>xpdiffat15</th>\n",
       "      <th>csdiffat15</th>\n",
       "      <th>killsat15</th>\n",
       "      <th>assistsat15</th>\n",
       "      <th>deathsat15</th>\n",
       "      <th>opp_killsat15</th>\n",
       "      <th>opp_assistsat15</th>\n",
       "      <th>opp_deathsat15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>top</td>\n",
       "      <td>Adam</td>\n",
       "      <td>Team BDS</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>-346.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>jng</td>\n",
       "      <td>Sheo</td>\n",
       "      <td>Team BDS</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-378.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>mid</td>\n",
       "      <td>nuc</td>\n",
       "      <td>Team BDS</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>152.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>-330.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>bot</td>\n",
       "      <td>Ice</td>\n",
       "      <td>Team BDS</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>sup</td>\n",
       "      <td>Labrov</td>\n",
       "      <td>Team BDS</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-1313.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    position playername  teamname  result  kills  deaths  assists  teamkills  \\\n",
       "216      top       Adam  Team BDS       0      3       3        3         10   \n",
       "217      jng       Sheo  Team BDS       0      2       2        2         10   \n",
       "218      mid        nuc  Team BDS       0      2       3        1         10   \n",
       "219      bot        Ice  Team BDS       0      2       2        2         10   \n",
       "220      sup     Labrov  Team BDS       0      1       4        3         10   \n",
       "\n",
       "     teamdeaths  firstblood  ...  opp_csat15  golddiffat15  xpdiffat15  \\\n",
       "216          14         1.0  ...       135.0        1690.0      -346.0   \n",
       "217          14         1.0  ...        95.0        -378.0        74.0   \n",
       "218          14         0.0  ...       152.0         279.0      -330.0   \n",
       "219          14         0.0  ...       109.0         213.0      1319.0   \n",
       "220          14         0.0  ...        23.0         -75.0     -1313.0   \n",
       "\n",
       "     csdiffat15  killsat15  assistsat15  deathsat15  opp_killsat15  \\\n",
       "216        -1.0        2.0          1.0         1.0            0.0   \n",
       "217         3.0        1.0          2.0         0.0            2.0   \n",
       "218       -16.0        1.0          0.0         0.0            0.0   \n",
       "219        17.0        2.0          1.0         2.0            3.0   \n",
       "220        -8.0        0.0          3.0         2.0            0.0   \n",
       "\n",
       "     opp_assistsat15  opp_deathsat15  \n",
       "216              1.0             2.0  \n",
       "217              2.0             0.0  \n",
       "218              1.0             0.0  \n",
       "219              1.0             2.0  \n",
       "220              3.0             2.0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_data(df):\n",
    "    # Drop columns: 'gameid', 'datacompleteness' and 50 other columns\n",
    "    df = df.drop(columns=['gameid', 'datacompleteness', 'url', 'league', 'split', 'year', 'playoffs', 'date', 'game', 'patch', 'participantid', 'side', 'teamid', 'champion', 'ban1', 'ban2', 'ban3', 'ban4', 'ban5', 'gamelength', 'doublekills', 'triplekills', 'quadrakills', 'pentakills', 'firstbloodassist', 'firstbloodkill', 'firstbloodvictim', 'firstdragon', 'dragons', 'opp_dragons', 'elementaldrakes', 'infernals', 'opp_elementaldrakes', 'mountains', 'clouds', 'oceans', 'chemtechs', 'hextechs', 'dragons (type unknown)', 'elders', 'opp_elders', 'firstherald', 'heralds', 'opp_heralds', 'firstbaron', 'firsttower', 'towers', 'opp_towers', 'firstmidtower', 'firsttothreetowers', 'turretplates', 'opp_turretplates'])\n",
    "    # Drop rows with missing data in columns: 'playername', 'result'\n",
    "    df = df.dropna(subset=['playername', 'result'])\n",
    "    # Drop column: 'gspd'\n",
    "    df = df.drop(columns=['gspd'])\n",
    "    # Drop column: 'monsterkillsenemyjungle'\n",
    "    df = df.drop(columns=['monsterkillsenemyjungle'])\n",
    "    # Drop column: 'monsterkillsownjungle'\n",
    "    df = df.drop(columns=['monsterkillsownjungle'])\n",
    "    # Drop rows with missing data across all columns\n",
    "    df = df.dropna()\n",
    "    # Drop column: 'playerid'\n",
    "    df = df.drop(columns=['playerid'])\n",
    "    # Export DataFrame to an Excel file\n",
    "    df.to_excel(\"output.xlsx\", index=False)\n",
    "    return df\n",
    "\n",
    "# Loaded variable 'df' from URI: c:\\Users\\ssjed\\OneDrive\\Documents\\GitHub\\Fall2024\\STAT 335\\Final\\2024_LoL_esports_match_data_from_OraclesElixir.xlsx\n",
    "df = pd.read_excel(r'c:\\Users\\ssjed\\OneDrive\\Documents\\GitHub\\Fall2024\\STAT 335\\Final\\2024_LoL_esports_match_data_from_OraclesElixir.xlsx')\n",
    "\n",
    "df_clean = clean_data(df.copy())\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result                      1.000000\n",
       "team kpm                    0.687156\n",
       "teamkills                   0.668952\n",
       "teamdeaths                  0.667032\n",
       "assists                     0.527882\n",
       "                              ...   \n",
       "wardsplaced                 0.021534\n",
       "damagemitigatedperminute    0.020690\n",
       "damageshare                 0.000685\n",
       "earnedgoldshare             0.000041\n",
       "ckpm                        0.000017\n",
       "Name: result, Length: 64, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only numeric columns\n",
    "numeric_df_clean = df_clean.select_dtypes(include=['number'])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numeric_df_clean.corr()\n",
    "\n",
    "# Get the absolute values of the correlation matrix\n",
    "abs_correlation_matrix = correlation_matrix.abs()\n",
    "\n",
    "# Unstack the matrix and sort by correlation value\n",
    "sorted_correlations = abs_correlation_matrix.unstack().sort_values(ascending=False)\n",
    "\n",
    "# Drop the duplicate pairs (correlation of a variable with itself)\n",
    "sorted_correlations = sorted_correlations[sorted_correlations != 1]\n",
    "\n",
    "# Display the sorted correlations\n",
    "sorted_correlations\n",
    "\n",
    "# Calculate the correlation of 'result' with all other columns\n",
    "result_correlations = abs_correlation_matrix['result']\n",
    "\n",
    "# Sort the correlations by absolute value in descending order\n",
    "sorted_result_correlations = result_correlations.sort_values(ascending=False)\n",
    "\n",
    "# Display the sorted correlations\n",
    "sorted_result_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "csat15           csat10             0.983146\n",
       "csat10           csat15             0.983146\n",
       "opp_csat10       opp_csat15         0.983115\n",
       "opp_csat15       opp_csat10         0.983115\n",
       "totalgold        earnedgold         0.982773\n",
       "                                      ...   \n",
       "earnedgoldshare  team kpm           0.000105\n",
       "result           earnedgoldshare    0.000041\n",
       "earnedgoldshare  result             0.000041\n",
       "ckpm             result             0.000017\n",
       "result           ckpm               0.000017\n",
       "Length: 4032, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only numeric columns\n",
    "numeric_df_clean = df_clean.select_dtypes(include=['number'])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numeric_df_clean.corr()\n",
    "\n",
    "# Get the absolute values of the correlation matrix\n",
    "abs_correlation_matrix = correlation_matrix.abs()\n",
    "\n",
    "# Unstack the matrix and sort by correlation value\n",
    "sorted_correlations = abs_correlation_matrix.unstack().sort_values(ascending=False)\n",
    "\n",
    "# Drop the duplicate pairs (correlation of a variable with itself)\n",
    "sorted_correlations = sorted_correlations[sorted_correlations != 1]\n",
    "\n",
    "# Display the sorted correlations\n",
    "sorted_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for position: top\n",
      "    position   playername      teamname  result  kills  deaths  assists  \\\n",
      "216      top         Adam      Team BDS       0      3       3        3   \n",
      "221      top  BrokenBlade    G2 Esports       1      4       3        2   \n",
      "228      top     Szygenda         Rogue       0      0       3        2   \n",
      "233      top   Irrelevant     SK Gaming       1      6       1        6   \n",
      "240      top    Cabochard  Karmine Corp       0      0       4        4   \n",
      "\n",
      "     teamkills  teamdeaths  firstblood  ...  opp_csat15  golddiffat15  \\\n",
      "216         10          14         1.0  ...       135.0        1690.0   \n",
      "221         14          10         0.0  ...       134.0       -1690.0   \n",
      "228          4          16         0.0  ...       133.0        -136.0   \n",
      "233         16           4         0.0  ...       118.0         136.0   \n",
      "240          9          20         0.0  ...       142.0        -175.0   \n",
      "\n",
      "     xpdiffat15  csdiffat15  killsat15  assistsat15  deathsat15  \\\n",
      "216      -346.0        -1.0        2.0          1.0         1.0   \n",
      "221       346.0         1.0        0.0          1.0         2.0   \n",
      "228      -484.0       -15.0        0.0          0.0         1.0   \n",
      "233       484.0        15.0        1.0          0.0         0.0   \n",
      "240       601.0        -7.0        0.0          0.0         0.0   \n",
      "\n",
      "     opp_killsat15  opp_assistsat15  opp_deathsat15  \n",
      "216            0.0              1.0             2.0  \n",
      "221            2.0              1.0             1.0  \n",
      "228            1.0              0.0             0.0  \n",
      "233            0.0              0.0             1.0  \n",
      "240            0.0              0.0             0.0  \n",
      "\n",
      "[5 rows x 67 columns]\n",
      "\n",
      "\n",
      "Dataset for position: jng\n",
      "    position playername      teamname  result  kills  deaths  assists  \\\n",
      "217      jng       Sheo      Team BDS       0      2       2        2   \n",
      "222      jng       Yike    G2 Esports       1      4       1        5   \n",
      "229      jng    Markoon         Rogue       0      0       3        4   \n",
      "234      jng       ISMA     SK Gaming       1      3       0       12   \n",
      "241      jng         Bo  Karmine Corp       0      3       7        1   \n",
      "\n",
      "     teamkills  teamdeaths  firstblood  ...  opp_csat15  golddiffat15  \\\n",
      "217         10          14         1.0  ...        95.0        -378.0   \n",
      "222         14          10         0.0  ...        98.0         378.0   \n",
      "229          4          16         0.0  ...        94.0        -342.0   \n",
      "234         16           4         1.0  ...       119.0         342.0   \n",
      "241          9          20         0.0  ...        95.0        -227.0   \n",
      "\n",
      "     xpdiffat15  csdiffat15  killsat15  assistsat15  deathsat15  \\\n",
      "217        74.0         3.0        1.0          2.0         0.0   \n",
      "222       -74.0        -3.0        2.0          2.0         0.0   \n",
      "229       129.0        25.0        0.0          1.0         0.0   \n",
      "234      -129.0       -25.0        1.0          2.0         0.0   \n",
      "241       806.0        13.0        1.0          0.0         1.0   \n",
      "\n",
      "     opp_killsat15  opp_assistsat15  opp_deathsat15  \n",
      "217            2.0              2.0             0.0  \n",
      "222            1.0              2.0             0.0  \n",
      "229            1.0              2.0             0.0  \n",
      "234            0.0              1.0             0.0  \n",
      "241            2.0              0.0             1.0  \n",
      "\n",
      "[5 rows x 67 columns]\n",
      "\n",
      "\n",
      "Dataset for position: mid\n",
      "    position playername      teamname  result  kills  deaths  assists  \\\n",
      "218      mid        nuc      Team BDS       0      2       3        1   \n",
      "223      mid       Caps    G2 Esports       1      2       0        7   \n",
      "230      mid    Larssen         Rogue       0      1       5        3   \n",
      "235      mid      Nisqy     SK Gaming       1      1       2        6   \n",
      "242      mid      SAKEN  Karmine Corp       0      3       2        4   \n",
      "\n",
      "     teamkills  teamdeaths  firstblood  ...  opp_csat15  golddiffat15  \\\n",
      "218         10          14         0.0  ...       152.0         279.0   \n",
      "223         14          10         0.0  ...       136.0        -279.0   \n",
      "230          4          16         0.0  ...       128.0        -262.0   \n",
      "235         16           4         1.0  ...       131.0         262.0   \n",
      "242          9          20         0.0  ...       145.0        -391.0   \n",
      "\n",
      "     xpdiffat15  csdiffat15  killsat15  assistsat15  deathsat15  \\\n",
      "218      -330.0       -16.0        1.0          0.0         0.0   \n",
      "223       330.0        16.0        0.0          1.0         0.0   \n",
      "230        15.0         3.0        0.0          1.0         2.0   \n",
      "235       -15.0        -3.0        1.0          1.0         1.0   \n",
      "242      -779.0       -13.0        0.0          1.0         0.0   \n",
      "\n",
      "     opp_killsat15  opp_assistsat15  opp_deathsat15  \n",
      "218            0.0              1.0             0.0  \n",
      "223            1.0              0.0             0.0  \n",
      "230            1.0              1.0             1.0  \n",
      "235            0.0              1.0             2.0  \n",
      "242            0.0              1.0             0.0  \n",
      "\n",
      "[5 rows x 67 columns]\n",
      "\n",
      "\n",
      "Dataset for position: bot\n",
      "    position playername      teamname  result  kills  deaths  assists  \\\n",
      "219      bot        Ice      Team BDS       0      2       2        2   \n",
      "224      bot  Hans Sama    G2 Esports       1      4       2        5   \n",
      "231      bot       Comp         Rogue       0      3       2        0   \n",
      "236      bot    Exakick     SK Gaming       1      5       1        5   \n",
      "243      bot      Upset  Karmine Corp       0      2       2        3   \n",
      "\n",
      "     teamkills  teamdeaths  firstblood  ...  opp_csat15  golddiffat15  \\\n",
      "219         10          14         0.0  ...       109.0         213.0   \n",
      "224         14          10         0.0  ...       126.0        -213.0   \n",
      "231          4          16         0.0  ...       142.0         639.0   \n",
      "236         16           4         0.0  ...       155.0        -639.0   \n",
      "243          9          20         0.0  ...       128.0         342.0   \n",
      "\n",
      "     xpdiffat15  csdiffat15  killsat15  assistsat15  deathsat15  \\\n",
      "219      1319.0        17.0        2.0          1.0         2.0   \n",
      "224     -1319.0       -17.0        3.0          1.0         2.0   \n",
      "231       875.0        13.0        1.0          0.0         0.0   \n",
      "236      -875.0       -13.0        0.0          0.0         0.0   \n",
      "243       249.0        12.0        0.0          1.0         0.0   \n",
      "\n",
      "     opp_killsat15  opp_assistsat15  opp_deathsat15  \n",
      "219            3.0              1.0             2.0  \n",
      "224            2.0              1.0             2.0  \n",
      "231            0.0              0.0             0.0  \n",
      "236            1.0              0.0             0.0  \n",
      "243            0.0              1.0             0.0  \n",
      "\n",
      "[5 rows x 67 columns]\n",
      "\n",
      "\n",
      "Dataset for position: sup\n",
      "    position playername      teamname  result  kills  deaths  assists  \\\n",
      "220      sup     Labrov      Team BDS       0      1       4        3   \n",
      "225      sup      Mikyx    G2 Esports       1      0       4        7   \n",
      "232      sup     Zoelys         Rogue       0      0       3        4   \n",
      "237      sup       Doss     SK Gaming       1      1       0       14   \n",
      "244      sup   Targamas  Karmine Corp       0      1       5        4   \n",
      "\n",
      "     teamkills  teamdeaths  firstblood  ...  opp_csat15  golddiffat15  \\\n",
      "220         10          14         0.0  ...        23.0         -75.0   \n",
      "225         14          10         0.0  ...        15.0          75.0   \n",
      "232          4          16         0.0  ...        14.0        -230.0   \n",
      "237         16           4         1.0  ...        16.0         230.0   \n",
      "244          9          20         0.0  ...        13.0         -10.0   \n",
      "\n",
      "     xpdiffat15  csdiffat15  killsat15  assistsat15  deathsat15  \\\n",
      "220     -1313.0        -8.0        0.0          3.0         2.0   \n",
      "225      1313.0         8.0        0.0          3.0         2.0   \n",
      "232      -143.0         2.0        0.0          1.0         0.0   \n",
      "237       143.0        -2.0        0.0          3.0         0.0   \n",
      "244      -579.0         9.0        0.0          1.0         1.0   \n",
      "\n",
      "     opp_killsat15  opp_assistsat15  opp_deathsat15  \n",
      "220            0.0              3.0             2.0  \n",
      "225            0.0              3.0             2.0  \n",
      "232            0.0              3.0             0.0  \n",
      "237            0.0              1.0             0.0  \n",
      "244            0.0              1.0             0.0  \n",
      "\n",
      "[5 rows x 67 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create datasets based on position\n",
    "positions = ['top', 'jng', 'mid', 'bot', 'sup']\n",
    "datasets = {}\n",
    "\n",
    "for position in positions:\n",
    "    datasets[position] = df_clean[df_clean['position'] == position]\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "for position, dataset in datasets.items():\n",
    "    print(f\"Dataset for position: {position}\")\n",
    "    print(dataset.head())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created top_dataset.xlsx\n",
      "Created jng_dataset.xlsx\n",
      "Created mid_dataset.xlsx\n",
      "Created bot_dataset.xlsx\n",
      "Created sup_dataset.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create an Excel file for each role\n",
    "for position, dataset in datasets.items():\n",
    "    filename = f\"{position}_dataset.xlsx\"\n",
    "    dataset.to_excel(filename, index=False)\n",
    "    print(f\"Created {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved top_dataset.xlsx to roles/top_dataset.xlsx\n",
      "Moved jng_dataset.xlsx to roles/jng_dataset.xlsx\n",
      "Moved mid_dataset.xlsx to roles/mid_dataset.xlsx\n",
      "Moved bot_dataset.xlsx to roles/bot_dataset.xlsx\n",
      "Moved sup_dataset.xlsx to roles/sup_dataset.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Create the 'roles' directory if it doesn't exist\n",
    "if not os.path.exists('roles'):\n",
    "    os.makedirs('roles')\n",
    "\n",
    "# Move the Excel files to the 'roles' directory\n",
    "for position, dataset in datasets.items():\n",
    "    filename = f\"{position}_dataset.xlsx\"\n",
    "    destination = os.path.join('roles', filename)\n",
    "    if os.path.exists(destination):\n",
    "        os.remove(destination)\n",
    "    os.rename(filename, destination)\n",
    "    print(f\"Moved {filename} to roles/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9610077984403119\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       846\n",
      "           1       0.96      0.96      0.96       821\n",
      "\n",
      "    accuracy                           0.96      1667\n",
      "   macro avg       0.96      0.96      0.96      1667\n",
      "weighted avg       0.96      0.96      0.96      1667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features = numeric_df_clean.drop(columns=['result'])\n",
    "target = numeric_df_clean['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=8334)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.053815\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.056230\n",
      "         Iterations 12\n",
      "Selected Features: ['assists', 'teamkills', 'teamdeaths', 'team kpm', 'ckpm', 'inhibitors', 'opp_inhibitors', 'wardsplaced', 'visionscore', 'earned gpm', 'earnedgoldshare', 'goldspent', 'minionkills', 'cspm', 'csat15', 'opp_goldat15', 'opp_csat15', 'killsat15', 'assistsat15', 'opp_killsat15', 'opp_assistsat15']\n",
      "Accuracy: 0.976004799040192\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       846\n",
      "           1       0.98      0.98      0.98       821\n",
      "\n",
      "    accuracy                           0.98      1667\n",
      "   macro avg       0.98      0.98      0.98      1667\n",
      "weighted avg       0.98      0.98      0.98      1667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Add a constant to the features\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "\n",
    "# Fit the initial model with all features\n",
    "model = sm.Logit(y_train, X_train_const).fit()\n",
    "\n",
    "# Perform backward selection\n",
    "def backward_selection(data, target, significance_level=0.05):\n",
    "    features = data.columns.tolist()\n",
    "    while len(features) > 0:\n",
    "        X = sm.add_constant(data[features])\n",
    "        model = sm.Logit(target, X).fit(disp=0)\n",
    "        p_values = model.pvalues[1:]  # Exclude the intercept\n",
    "        max_p_value = p_values.max()\n",
    "        if max_p_value > significance_level:\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else:\n",
    "            break\n",
    "    return features\n",
    "\n",
    "# Run backward selection\n",
    "selected_features = backward_selection(X_train, y_train)\n",
    "\n",
    "# Fit the final model with selected features\n",
    "X_train_selected = sm.add_constant(X_train[selected_features])\n",
    "final_model = sm.Logit(y_train, X_train_selected).fit()\n",
    "\n",
    "# Evaluate the final model\n",
    "X_test_selected = sm.add_constant(X_test[selected_features])\n",
    "y_pred = final_model.predict(X_test_selected)\n",
    "y_pred_class = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_class)\n",
    "report = classification_report(y_test, y_pred_class)\n",
    "\n",
    "print(f'Selected Features: {selected_features}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position: top\n",
      "Accuracy: 0.972972972972973\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       165\n",
      "           1       0.96      0.98      0.97       168\n",
      "\n",
      "    accuracy                           0.97       333\n",
      "   macro avg       0.97      0.97      0.97       333\n",
      "weighted avg       0.97      0.97      0.97       333\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position: jng\n",
      "Accuracy: 0.9670658682634731\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       169\n",
      "           1       0.97      0.96      0.97       165\n",
      "\n",
      "    accuracy                           0.97       334\n",
      "   macro avg       0.97      0.97      0.97       334\n",
      "weighted avg       0.97      0.97      0.97       334\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position: mid\n",
      "Accuracy: 0.9640718562874252\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       169\n",
      "           1       0.98      0.95      0.96       165\n",
      "\n",
      "    accuracy                           0.96       334\n",
      "   macro avg       0.96      0.96      0.96       334\n",
      "weighted avg       0.96      0.96      0.96       334\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position: bot\n",
      "Accuracy: 0.9579579579579579\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       181\n",
      "           1       0.96      0.95      0.95       152\n",
      "\n",
      "    accuracy                           0.96       333\n",
      "   macro avg       0.96      0.96      0.96       333\n",
      "weighted avg       0.96      0.96      0.96       333\n",
      "\n",
      "\n",
      "\n",
      "Position: sup\n",
      "Accuracy: 0.9520958083832335\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       164\n",
      "           1       0.94      0.96      0.95       170\n",
      "\n",
      "    accuracy                           0.95       334\n",
      "   macro avg       0.95      0.95      0.95       334\n",
      "weighted avg       0.95      0.95      0.95       334\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Iterate through each dataset in the roles folder\n",
    "for position, dataset in datasets.items():\n",
    "    # Select only numeric columns\n",
    "    numeric_dataset = dataset.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Define the feature columns and target variable\n",
    "    features = numeric_dataset.drop(columns=['result'])\n",
    "    target = numeric_dataset['result']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create and train the logistic regression model\n",
    "    model = LogisticRegression(max_iter=8334)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f'Position: {position}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print('Classification Report:')\n",
    "    print(report)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049551\n",
      "         Iterations 12\n",
      "Position: top\n",
      "Selected Features: ['assists', 'teamdeaths', 'team kpm', 'ckpm', 'barons', 'opp_inhibitors', 'damagetochampions', 'dpm', 'damageshare', 'earned gpm', 'earnedgoldshare', 'goldspent', 'opp_xpat10', 'opp_xpat15']\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 result   No. Observations:                 1664\n",
      "Model:                          Logit   Df Residuals:                     1649\n",
      "Method:                           MLE   Df Model:                           14\n",
      "Date:                Mon, 25 Nov 2024   Pseudo R-squ.:                  0.9285\n",
      "Time:                        14:44:08   Log-Likelihood:                -82.452\n",
      "converged:                       True   LL-Null:                       -1153.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=====================================================================================\n",
      "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                15.0968      4.280      3.527      0.000       6.708      23.486\n",
      "assists               0.1763      0.085      2.070      0.038       0.009       0.343\n",
      "teamdeaths            1.2651      0.260      4.874      0.000       0.756       1.774\n",
      "team kpm             61.0574     11.658      5.237      0.000      38.209      83.906\n",
      "ckpm                -64.2092     10.865     -5.910      0.000     -85.505     -42.914\n",
      "barons               -2.4445      0.895     -2.730      0.006      -4.199      -0.690\n",
      "opp_inhibitors       -2.0823      0.532     -3.912      0.000      -3.126      -1.039\n",
      "damagetochampions    -0.0005      0.000     -2.565      0.010      -0.001      -0.000\n",
      "dpm                   0.0255      0.008      3.042      0.002       0.009       0.042\n",
      "damageshare         -17.6677      7.531     -2.346      0.019     -32.428      -2.908\n",
      "earned gpm            0.2103      0.025      8.410      0.000       0.161       0.259\n",
      "earnedgoldshare    -208.3492     27.503     -7.576      0.000    -262.254    -154.445\n",
      "goldspent            -0.0010      0.000     -4.032      0.000      -0.001      -0.000\n",
      "opp_xpat10            0.0025      0.001      2.539      0.011       0.001       0.004\n",
      "opp_xpat15           -0.0018      0.001     -3.096      0.002      -0.003      -0.001\n",
      "=====================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.61 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.037739\n",
      "         Iterations 12\n",
      "Position: jng\n",
      "Selected Features: ['assists', 'team kpm', 'ckpm', 'inhibitors', 'opp_inhibitors', 'damagemitigatedperminute', 'wardsplaced', 'visionscore', 'earnedgold', 'earned gpm', 'earnedgoldshare', 'goldspent', 'csdiffat10', 'opp_killsat10', 'opp_xpat15', 'opp_csat15', 'killsat15', 'assistsat15', 'opp_killsat15', 'opp_assistsat15']\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 result   No. Observations:                 1668\n",
      "Model:                          Logit   Df Residuals:                     1647\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Mon, 25 Nov 2024   Pseudo R-squ.:                  0.9456\n",
      "Time:                        14:44:12   Log-Likelihood:                -62.949\n",
      "converged:                       True   LL-Null:                       -1156.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "============================================================================================\n",
      "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                       20.4735      4.753      4.308      0.000      11.158      29.788\n",
      "assists                      0.2467      0.104      2.375      0.018       0.043       0.450\n",
      "team kpm                    27.2992      5.303      5.148      0.000      16.906      37.692\n",
      "ckpm                       -23.1318      3.241     -7.138      0.000     -29.483     -16.780\n",
      "inhibitors                   2.2308      0.876      2.545      0.011       0.513       3.948\n",
      "opp_inhibitors              -2.2158      0.830     -2.669      0.008      -3.843      -0.589\n",
      "damagemitigatedperminute    -0.0015      0.001     -2.066      0.039      -0.003   -7.66e-05\n",
      "wardsplaced                 -0.0952      0.047     -2.023      0.043      -0.188      -0.003\n",
      "visionscore                  0.0716      0.027      2.603      0.009       0.018       0.125\n",
      "earnedgold                   0.0029      0.001      3.857      0.000       0.001       0.004\n",
      "earned gpm                   0.2094      0.036      5.814      0.000       0.139       0.280\n",
      "earnedgoldshare           -292.9978     43.392     -6.752      0.000    -378.044    -207.951\n",
      "goldspent                   -0.0022      0.000     -4.931      0.000      -0.003      -0.001\n",
      "csdiffat10                   0.0782      0.032      2.474      0.013       0.016       0.140\n",
      "opp_killsat10               -1.6117      0.564     -2.859      0.004      -2.717      -0.507\n",
      "opp_xpat15                  -0.0036      0.001     -2.875      0.004      -0.006      -0.001\n",
      "opp_csat15                   0.1578      0.059      2.679      0.007       0.042       0.273\n",
      "killsat15                   -0.9808      0.327     -2.999      0.003      -1.622      -0.340\n",
      "assistsat15                 -0.5704      0.202     -2.820      0.005      -0.967      -0.174\n",
      "opp_killsat15                2.0959      0.487      4.301      0.000       1.141       3.051\n",
      "opp_assistsat15              0.9671      0.265      3.655      0.000       0.449       1.486\n",
      "============================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.69 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.039345\n",
      "         Iterations 13\n",
      "Position: mid\n",
      "Selected Features: ['assists', 'teamdeaths', 'team kpm', 'ckpm', 'opp_barons', 'inhibitors', 'opp_inhibitors', 'totalgold', 'earnedgold', 'earned gpm', 'earnedgoldshare', 'goldspent', 'total cs', 'monsterkills', 'cspm', 'csdiffat10', 'golddiffat15', 'assistsat15', 'opp_killsat15', 'opp_assistsat15']\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 result   No. Observations:                 1668\n",
      "Model:                          Logit   Df Residuals:                     1647\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Mon, 25 Nov 2024   Pseudo R-squ.:                  0.9432\n",
      "Time:                        14:44:16   Log-Likelihood:                -65.627\n",
      "converged:                       True   LL-Null:                       -1156.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              78.2911     23.779      3.292      0.001      31.685     124.897\n",
      "assists             0.4343      0.131      3.315      0.001       0.178       0.691\n",
      "teamdeaths          1.4526      0.455      3.193      0.001       0.561       2.344\n",
      "team kpm           71.5711     18.776      3.812      0.000      34.771     108.371\n",
      "ckpm              -75.1039     18.737     -4.008      0.000    -111.827     -38.381\n",
      "opp_barons         -2.5534      1.183     -2.159      0.031      -4.871      -0.235\n",
      "inhibitors          2.0651      0.591      3.497      0.000       0.908       3.223\n",
      "opp_inhibitors     -2.0832      0.547     -3.809      0.000      -3.155      -1.011\n",
      "totalgold          -0.0126      0.004     -2.929      0.003      -0.021      -0.004\n",
      "earnedgold          0.0099      0.004      2.349      0.019       0.002       0.018\n",
      "earned gpm          0.2957      0.062      4.749      0.000       0.174       0.418\n",
      "earnedgoldshare  -197.4864     28.796     -6.858      0.000    -253.926    -141.046\n",
      "goldspent          -0.0006      0.000     -3.643      0.000      -0.001      -0.000\n",
      "total cs            0.2113      0.071      2.989      0.003       0.073       0.350\n",
      "monsterkills        0.0874      0.030      2.948      0.003       0.029       0.146\n",
      "cspm               -9.0085      2.806     -3.211      0.001     -14.508      -3.509\n",
      "csdiffat10          0.1139      0.031      3.690      0.000       0.053       0.174\n",
      "golddiffat15        0.0012      0.001      2.342      0.019       0.000       0.002\n",
      "assistsat15        -1.1094      0.291     -3.817      0.000      -1.679      -0.540\n",
      "opp_killsat15       0.9025      0.340      2.651      0.008       0.235       1.570\n",
      "opp_assistsat15     0.6048      0.235      2.570      0.010       0.144       1.066\n",
      "===================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.71 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.041358\n",
      "         Iterations 13\n",
      "Position: bot\n",
      "Selected Features: ['teamkills', 'teamdeaths', 'team kpm', 'ckpm', 'opp_inhibitors', 'damagetochampions', 'wardsplaced', 'wardskilled', 'wcpm', 'earned gpm', 'earnedgoldshare', 'goldspent', 'xpat10', 'opp_goldat10', 'opp_xpat10', 'golddiffat10', 'csdiffat10', 'killsat10', 'assistsat10', 'opp_killsat10', 'opp_assistsat10', 'opp_goldat15', 'golddiffat15', 'xpdiffat15', 'csdiffat15']\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 result   No. Observations:                 1664\n",
      "Model:                          Logit   Df Residuals:                     1638\n",
      "Method:                           MLE   Df Model:                           25\n",
      "Date:                Mon, 25 Nov 2024   Pseudo R-squ.:                  0.9403\n",
      "Time:                        14:44:21   Log-Likelihood:                -68.819\n",
      "converged:                       True   LL-Null:                       -1153.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=====================================================================================\n",
      "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                20.1611      6.398      3.151      0.002       7.622      32.700\n",
      "teamkills            -0.9316      0.370     -2.518      0.012      -1.657      -0.206\n",
      "teamdeaths            1.4870      0.391      3.803      0.000       0.721       2.253\n",
      "team kpm            111.8598     28.795      3.885      0.000      55.423     168.297\n",
      "ckpm                -74.8523     15.997     -4.679      0.000    -106.206     -43.499\n",
      "opp_inhibitors       -1.6017      0.480     -3.336      0.001      -2.543      -0.661\n",
      "damagetochampions     0.0001    3.7e-05      3.099      0.002    4.22e-05       0.000\n",
      "wardsplaced          -0.0737      0.029     -2.584      0.010      -0.130      -0.018\n",
      "wardskilled           0.5175      0.245      2.116      0.034       0.038       0.997\n",
      "wcpm                -19.8140      9.298     -2.131      0.033     -38.038      -1.590\n",
      "earned gpm            0.2017      0.029      7.028      0.000       0.145       0.258\n",
      "earnedgoldshare    -213.6141     31.460     -6.790      0.000    -275.274    -151.954\n",
      "goldspent            -0.0012      0.000     -4.784      0.000      -0.002      -0.001\n",
      "xpat10                0.0037      0.001      2.561      0.010       0.001       0.007\n",
      "opp_goldat10          0.0052      0.002      2.087      0.037       0.000       0.010\n",
      "opp_xpat10           -0.0051      0.001     -3.459      0.001      -0.008      -0.002\n",
      "golddiffat10          0.0117      0.003      4.373      0.000       0.006       0.017\n",
      "csdiffat10           -0.2785      0.063     -4.417      0.000      -0.402      -0.155\n",
      "killsat10            -2.4388      0.775     -3.147      0.002      -3.958      -0.920\n",
      "assistsat10          -1.4913      0.471     -3.167      0.002      -2.414      -0.569\n",
      "opp_killsat10         2.3020      0.657      3.502      0.000       1.013       3.591\n",
      "opp_assistsat10       1.2643      0.368      3.439      0.001       0.544       1.985\n",
      "opp_goldat15         -0.0028      0.001     -2.435      0.015      -0.005      -0.001\n",
      "golddiffat15         -0.0031      0.001     -3.626      0.000      -0.005      -0.001\n",
      "xpdiffat15           -0.0024      0.001     -2.826      0.005      -0.004      -0.001\n",
      "csdiffat15            0.1225      0.038      3.226      0.001       0.048       0.197\n",
      "=====================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.70 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\ssjed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.034819\n",
      "         Iterations 14\n",
      "Position: sup\n",
      "Selected Features: ['teamdeaths', 'team kpm', 'ckpm', 'damageshare', 'damagetakenperminute', 'controlwardsbought', 'earned gpm', 'earnedgoldshare', 'goldspent', 'total cs', 'goldat10', 'opp_csat10', 'xpdiffat10', 'deathsat10', 'opp_killsat10', 'opp_assistsat10', 'opp_deathsat10', 'opp_xpat15', 'golddiffat15', 'csdiffat15', 'killsat15', 'assistsat15', 'opp_killsat15', 'opp_assistsat15', 'opp_deathsat15']\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 result   No. Observations:                 1670\n",
      "Model:                          Logit   Df Residuals:                     1644\n",
      "Method:                           MLE   Df Model:                           25\n",
      "Date:                Mon, 25 Nov 2024   Pseudo R-squ.:                  0.9498\n",
      "Time:                        14:44:25   Log-Likelihood:                -58.148\n",
      "converged:                       True   LL-Null:                       -1157.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                   19.8577      5.216      3.807      0.000       9.635      30.080\n",
      "teamdeaths               1.0919      0.254      4.297      0.000       0.594       1.590\n",
      "team kpm                82.9723     14.546      5.704      0.000      54.464     111.481\n",
      "ckpm                   -75.0250     13.226     -5.673      0.000    -100.947     -49.103\n",
      "damageshare            -41.6112     10.072     -4.131      0.000     -61.352     -21.870\n",
      "damagetakenperminute     0.0075      0.002      3.125      0.002       0.003       0.012\n",
      "controlwardsbought      -0.2165      0.070     -3.114      0.002      -0.353      -0.080\n",
      "earned gpm               0.6418      0.102      6.293      0.000       0.442       0.842\n",
      "earnedgoldshare       -651.0751    108.076     -6.024      0.000    -862.900    -439.251\n",
      "goldspent               -0.0021      0.000     -4.495      0.000      -0.003      -0.001\n",
      "total cs                 0.0808      0.025      3.293      0.001       0.033       0.129\n",
      "goldat10                 0.0039      0.002      2.449      0.014       0.001       0.007\n",
      "opp_csat10              -0.2380      0.067     -3.555      0.000      -0.369      -0.107\n",
      "xpdiffat10              -0.0035      0.001     -3.557      0.000      -0.005      -0.002\n",
      "deathsat10               1.5558      0.649      2.397      0.017       0.284       2.828\n",
      "opp_killsat10           -4.4049      1.170     -3.764      0.000      -6.699      -2.111\n",
      "opp_assistsat10         -1.5248      0.556     -2.744      0.006      -2.614      -0.436\n",
      "opp_deathsat10           1.3850      0.665      2.082      0.037       0.081       2.689\n",
      "opp_xpat15              -0.0016      0.001     -2.108      0.035      -0.003      -0.000\n",
      "golddiffat15             0.0057      0.001      4.035      0.000       0.003       0.009\n",
      "csdiffat15              -0.1989      0.052     -3.809      0.000      -0.301      -0.097\n",
      "killsat15               -4.3367      0.971     -4.464      0.000      -6.241      -2.433\n",
      "assistsat15             -0.9462      0.283     -3.342      0.001      -1.501      -0.391\n",
      "opp_killsat15            5.5834      1.230      4.538      0.000       3.172       7.995\n",
      "opp_assistsat15          1.3738      0.361      3.802      0.000       0.666       2.082\n",
      "opp_deathsat15          -2.1341      0.630     -3.387      0.001      -3.369      -0.899\n",
      "========================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.80 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each dataset in the roles folder\n",
    "for position, dataset in datasets.items():\n",
    "    # Select only numeric columns\n",
    "    numeric_dataset = dataset.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Define the feature columns and target variable\n",
    "    features = numeric_dataset.drop(columns=['result'])\n",
    "    target = numeric_dataset['result']\n",
    "    \n",
    "    # Run backward selection\n",
    "    selected_features = backward_selection(features, target)\n",
    "    \n",
    "    # Fit the final model with selected features\n",
    "    X_train_selected = sm.add_constant(features[selected_features])\n",
    "    final_model = sm.Logit(target, X_train_selected).fit()\n",
    "    \n",
    "    # Display the selected features and model summary\n",
    "    print(f'Position: {position}')\n",
    "    print(f'Selected Features: {selected_features}')\n",
    "    print(final_model.summary())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9556088782243551\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       846\n",
      "           1       0.95      0.96      0.96       821\n",
      "\n",
      "    accuracy                           0.96      1667\n",
      "   macro avg       0.96      0.96      0.96      1667\n",
      "weighted avg       0.96      0.96      0.96      1667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features = numeric_df_clean.drop(columns=['result'])\n",
    "target = numeric_df_clean['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['teamkills', 'teamdeaths', 'team kpm', 'ckpm']\n",
      "Best Accuracy: 0.9868026394721056\n",
      "Final Model Accuracy: 0.9868026394721056\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       846\n",
      "           1       0.98      0.99      0.99       821\n",
      "\n",
      "    accuracy                           0.99      1667\n",
      "   macro avg       0.99      0.99      0.99      1667\n",
      "weighted avg       0.99      0.99      0.99      1667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Function to perform backward selection\n",
    "def backward_selection_rf(X_train, y_train, X_test, y_test, significance_level=0.05):\n",
    "    features = X_train.columns.tolist()\n",
    "    best_accuracy = 0\n",
    "    best_features = features.copy()\n",
    "    \n",
    "    while len(features) > 0:\n",
    "        # Train the Random Forest model\n",
    "        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf_model.fit(X_train[features], y_train)\n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        y_pred = rf_model.predict(X_test[features])\n",
    "        \n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_features = features.copy()\n",
    "        \n",
    "        # Get feature importances\n",
    "        importances = rf_model.feature_importances_\n",
    "        \n",
    "        # Find the least important feature\n",
    "        least_important_feature = features[np.argmin(importances)]\n",
    "        \n",
    "        # Remove the least important feature\n",
    "        features.remove(least_important_feature)\n",
    "    \n",
    "    return best_features, best_accuracy\n",
    "\n",
    "# Run backward selection\n",
    "selected_features_rf, best_accuracy_rf = backward_selection_rf(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Fit the final Random Forest model with selected features\n",
    "rf_model_final = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_final.fit(X_train[selected_features_rf], y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf_final = rf_model_final.predict(X_test[selected_features_rf])\n",
    "\n",
    "# Evaluate the final model\n",
    "accuracy_rf_final = accuracy_score(y_test, y_pred_rf_final)\n",
    "report_rf_final = classification_report(y_test, y_pred_rf_final)\n",
    "\n",
    "print(f'Selected Features: {selected_features_rf}')\n",
    "print(f'Best Accuracy: {best_accuracy_rf}')\n",
    "print('Final Model Accuracy:', accuracy_rf_final)\n",
    "print('Classification Report:')\n",
    "print(report_rf_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position: top\n",
      "Accuracy: 0.9579579579579579\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       165\n",
      "           1       0.95      0.96      0.96       168\n",
      "\n",
      "    accuracy                           0.96       333\n",
      "   macro avg       0.96      0.96      0.96       333\n",
      "weighted avg       0.96      0.96      0.96       333\n",
      "\n",
      "\n",
      "\n",
      "Position: jng\n",
      "Accuracy: 0.9431137724550899\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       169\n",
      "           1       0.94      0.95      0.94       165\n",
      "\n",
      "    accuracy                           0.94       334\n",
      "   macro avg       0.94      0.94      0.94       334\n",
      "weighted avg       0.94      0.94      0.94       334\n",
      "\n",
      "\n",
      "\n",
      "Position: mid\n",
      "Accuracy: 0.9640718562874252\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       169\n",
      "           1       0.97      0.96      0.96       165\n",
      "\n",
      "    accuracy                           0.96       334\n",
      "   macro avg       0.96      0.96      0.96       334\n",
      "weighted avg       0.96      0.96      0.96       334\n",
      "\n",
      "\n",
      "\n",
      "Position: bot\n",
      "Accuracy: 0.963963963963964\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       181\n",
      "           1       0.96      0.96      0.96       152\n",
      "\n",
      "    accuracy                           0.96       333\n",
      "   macro avg       0.96      0.96      0.96       333\n",
      "weighted avg       0.96      0.96      0.96       333\n",
      "\n",
      "\n",
      "\n",
      "Position: sup\n",
      "Accuracy: 0.9401197604790419\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.94       164\n",
      "           1       0.91      0.98      0.94       170\n",
      "\n",
      "    accuracy                           0.94       334\n",
      "   macro avg       0.94      0.94      0.94       334\n",
      "weighted avg       0.94      0.94      0.94       334\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Iterate through each dataset in the roles folder\n",
    "for position, dataset in datasets.items():\n",
    "    # Select only numeric columns\n",
    "    numeric_dataset = dataset.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Define the feature columns and target variable\n",
    "    features = numeric_dataset.drop(columns=['result'])\n",
    "    target = numeric_dataset['result']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create and train the Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f'Position: {position}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print('Classification Report:')\n",
    "    print(report)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position: top\n",
      "Selected Features: ['kills', 'deaths', 'assists', 'teamkills', 'teamdeaths', 'team kpm', 'ckpm', 'inhibitors', 'opp_inhibitors', 'damagetochampions', 'dpm', 'damageshare', 'damagetakenperminute', 'damagemitigatedperminute', 'wardsplaced', 'wpm', 'wardskilled', 'wcpm', 'controlwardsbought', 'visionscore', 'vspm', 'totalgold', 'earnedgold', 'earned gpm', 'earnedgoldshare', 'goldspent', 'total cs', 'minionkills', 'monsterkills', 'cspm', 'goldat10', 'xpat10', 'csat10', 'opp_goldat10', 'opp_xpat10', 'opp_csat10', 'golddiffat10', 'xpdiffat10', 'csdiffat10', 'deathsat10', 'goldat15', 'xpat15', 'csat15', 'opp_goldat15', 'opp_xpat15', 'opp_csat15', 'golddiffat15', 'xpdiffat15', 'csdiffat15', 'killsat15', 'assistsat15', 'deathsat15', 'opp_killsat15', 'opp_assistsat15', 'opp_deathsat15']\n",
      "Best Accuracy: 0.9669669669669669\n",
      "Final Model Accuracy: 0.9669669669669669\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       165\n",
      "           1       0.96      0.98      0.97       168\n",
      "\n",
      "    accuracy                           0.97       333\n",
      "   macro avg       0.97      0.97      0.97       333\n",
      "weighted avg       0.97      0.97      0.97       333\n",
      "\n",
      "\n",
      "\n",
      "Position: jng\n",
      "Selected Features: ['deaths', 'assists', 'teamkills', 'teamdeaths', 'team kpm', 'ckpm', 'barons', 'opp_barons', 'inhibitors', 'opp_inhibitors', 'damagetochampions', 'dpm', 'damageshare', 'damagetakenperminute', 'damagemitigatedperminute', 'wpm', 'controlwardsbought', 'visionscore', 'vspm', 'totalgold', 'earnedgold', 'earned gpm', 'earnedgoldshare', 'goldspent', 'cspm', 'goldat10', 'golddiffat10', 'opp_goldat15', 'xpdiffat15']\n",
      "Best Accuracy: 0.9610778443113772\n",
      "Final Model Accuracy: 0.9610778443113772\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       169\n",
      "           1       0.97      0.95      0.96       165\n",
      "\n",
      "    accuracy                           0.96       334\n",
      "   macro avg       0.96      0.96      0.96       334\n",
      "weighted avg       0.96      0.96      0.96       334\n",
      "\n",
      "\n",
      "\n",
      "Position: mid\n",
      "Selected Features: ['kills', 'deaths', 'assists', 'teamkills', 'teamdeaths', 'team kpm', 'ckpm', 'opp_barons', 'inhibitors', 'opp_inhibitors', 'damagetochampions', 'dpm', 'damageshare', 'damagetakenperminute', 'damagemitigatedperminute', 'wardsplaced', 'wpm', 'wardskilled', 'wcpm', 'controlwardsbought', 'visionscore', 'vspm', 'totalgold', 'earnedgold', 'earned gpm', 'earnedgoldshare', 'goldspent', 'total cs', 'minionkills', 'monsterkills', 'cspm', 'goldat10', 'xpat10', 'csat10', 'opp_goldat10', 'opp_xpat10', 'opp_csat10', 'golddiffat10', 'xpdiffat10', 'csdiffat10', 'killsat10', 'assistsat10', 'opp_assistsat10', 'goldat15', 'xpat15', 'csat15', 'opp_goldat15', 'opp_xpat15', 'opp_csat15', 'golddiffat15', 'xpdiffat15', 'csdiffat15', 'killsat15', 'assistsat15', 'deathsat15', 'opp_killsat15', 'opp_assistsat15']\n",
      "Best Accuracy: 0.9790419161676647\n",
      "Final Model Accuracy: 0.9790419161676647\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       169\n",
      "           1       0.99      0.97      0.98       165\n",
      "\n",
      "    accuracy                           0.98       334\n",
      "   macro avg       0.98      0.98      0.98       334\n",
      "weighted avg       0.98      0.98      0.98       334\n",
      "\n",
      "\n",
      "\n",
      "Position: bot\n",
      "Selected Features: ['kills', 'deaths', 'assists', 'teamkills', 'teamdeaths', 'team kpm', 'ckpm', 'inhibitors', 'opp_inhibitors', 'damagetochampions', 'dpm', 'damageshare', 'damagetakenperminute', 'damagemitigatedperminute', 'wardsplaced', 'wpm', 'visionscore', 'vspm', 'totalgold', 'earnedgold', 'earned gpm', 'earnedgoldshare', 'goldspent', 'total cs', 'minionkills', 'monsterkills', 'cspm', 'goldat10', 'csat10', 'opp_goldat10', 'opp_xpat10', 'golddiffat10', 'xpdiffat10', 'csdiffat10', 'goldat15', 'xpat15', 'csat15', 'opp_goldat15', 'opp_xpat15', 'golddiffat15', 'xpdiffat15', 'csdiffat15']\n",
      "Best Accuracy: 0.972972972972973\n",
      "Final Model Accuracy: 0.972972972972973\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       181\n",
      "           1       0.97      0.97      0.97       152\n",
      "\n",
      "    accuracy                           0.97       333\n",
      "   macro avg       0.97      0.97      0.97       333\n",
      "weighted avg       0.97      0.97      0.97       333\n",
      "\n",
      "\n",
      "\n",
      "Position: sup\n",
      "Selected Features: ['deaths', 'assists', 'teamkills', 'teamdeaths', 'team kpm', 'ckpm', 'inhibitors', 'opp_inhibitors', 'damagetochampions', 'dpm', 'damageshare', 'damagetakenperminute', 'damagemitigatedperminute', 'wardsplaced', 'wpm', 'wardskilled', 'wcpm', 'controlwardsbought', 'visionscore', 'vspm', 'totalgold', 'earnedgold', 'earned gpm', 'earnedgoldshare', 'goldspent', 'total cs', 'minionkills', 'cspm', 'goldat10', 'xpat10', 'csat10', 'opp_goldat10', 'opp_xpat10', 'opp_csat10', 'golddiffat10', 'xpdiffat10', 'csdiffat10', 'goldat15', 'xpat15', 'csat15', 'opp_goldat15', 'opp_xpat15', 'opp_csat15', 'golddiffat15', 'xpdiffat15', 'csdiffat15', 'assistsat15', 'opp_assistsat15']\n",
      "Best Accuracy: 0.9520958083832335\n",
      "Final Model Accuracy: 0.9520958083832335\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       164\n",
      "           1       0.93      0.98      0.95       170\n",
      "\n",
      "    accuracy                           0.95       334\n",
      "   macro avg       0.95      0.95      0.95       334\n",
      "weighted avg       0.95      0.95      0.95       334\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each dataset in the roles folder\n",
    "for position, dataset in datasets.items():\n",
    "    # Select only numeric columns\n",
    "    numeric_dataset = dataset.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Define the feature columns and target variable\n",
    "    features = numeric_dataset.drop(columns=['result'])\n",
    "    target = numeric_dataset['result']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Run backward selection\n",
    "    selected_features_rf, best_accuracy_rf = backward_selection_rf(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # Fit the final Random Forest model with selected features\n",
    "    rf_model_final = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model_final.fit(X_train[selected_features_rf], y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred_rf_final = rf_model_final.predict(X_test[selected_features_rf])\n",
    "    \n",
    "    # Evaluate the final model\n",
    "    accuracy_rf_final = accuracy_score(y_test, y_pred_rf_final)\n",
    "    report_rf_final = classification_report(y_test, y_pred_rf_final)\n",
    "    \n",
    "    print(f'Position: {position}')\n",
    "    print(f'Selected Features: {selected_features_rf}')\n",
    "    print(f'Best Accuracy: {best_accuracy_rf}')\n",
    "    print('Final Model Accuracy:', accuracy_rf_final)\n",
    "    print('Classification Report:')\n",
    "    print(report_rf_final)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
